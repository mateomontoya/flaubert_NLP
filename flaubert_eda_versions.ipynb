{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import html5lib\n",
    "import glob\n",
    "import codecs\n",
    "import os\n",
    "import cltk\n",
    "from cltk.tokenize.word import  WordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is /Users/mateomontoya/Desktop/work/projects_ongoing/flaubert2\n"
     ]
    }
   ],
   "source": [
    "print (\"The current working directory is\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'parsed.csv' does not exist: b'parsed.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9a2386fbb2be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflaubert_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parsed.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflaubert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'parsed.csv' does not exist: b'parsed.csv'"
     ]
    }
   ],
   "source": [
    "flaubert_data = pd.read_csv('parsed.csv')\n",
    "len(flaubert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flaubert_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = WordTokenizer('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def token_flaubert_data(column, dataframe):\n",
    "    folios_tokenized = []\n",
    "\n",
    "    for text in dataframe[column]:\n",
    "        if type(text)==str:\n",
    "            tokens = word_tokenizer.tokenize(text)\n",
    "            folios_tokenized.append(tokens)\n",
    "        else:\n",
    "            folios_tokenized.append(' ')\n",
    "    print(folios_tokenized[0])\n",
    "    return folios_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_text = token_flaubert_data('text', flaubert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(flaubert_data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_data['chapter'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flaubert_data['chapter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flaubert_data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_data['text_tokenized'] = flaubert_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_text = flaubert_data[['chapter', 'version','folio', 'text', 'text_tokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_chap_1 = flaubert_text[flaubert_text['chapter'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_chap_1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_chap_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_chap_1['version'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_versions = flaubert_data[['chapter', 'version', 'text_tokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flaubert_versions['version'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_versions[flaubert_versions['version'] == 'C'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_tokens_on_version(data, version_tag, extended_column):\n",
    "    versions = ['1', '2', '3', '4', '5', '6', 'C', 'D']\n",
    "    version_text = []\n",
    "    index = 0\n",
    "    for version in data['version']:\n",
    "        if version_tag == version:\n",
    "            version_text.extend(data[extended_column][index])\n",
    "        index += 1\n",
    "    return version_text\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_1 = combine_tokens_on_version(flaubert_versions, '1', 'text_tokenized')\n",
    "version_2 = combine_tokens_on_version(flaubert_versions, '2', 'text_tokenized')\n",
    "version_3 = combine_tokens_on_version(flaubert_versions, '3', 'text_tokenized')\n",
    "version_4 = combine_tokens_on_version(flaubert_versions, '4', 'text_tokenized')\n",
    "version_5 = combine_tokens_on_version(flaubert_versions, '5', 'text_tokenized')\n",
    "version_6 = combine_tokens_on_version(flaubert_versions, '6', 'text_tokenized')\n",
    "version_c = combine_tokens_on_version(flaubert_versions, 'C', 'text_tokenized')\n",
    "version_d = combine_tokens_on_version(flaubert_versions, 'D', 'text_tokenized')\n",
    "print(version_1[:5])\n",
    "print(version_c[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'version': ['1', '2', '3', '4', '5', '6', 'C', 'D'],\n",
    "        'token_text': [version_1, version_2, version_3, version_4, version_5, version_6, version_c, version_d]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_version = pd.DataFrame(data=data)\n",
    "flaubert_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_version['token_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_version[flaubert_version['version'] == '1']['token_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_1 = pd.DataFrame([w for w in flaubert_version[flaubert_version['version'] == '1']['token_text']])\n",
    "draft_1 = draft_1.T\n",
    "draft_1['Tokens'] = draft_1[0]\n",
    "draft_1 = draft_1.drop(columns=[0])\n",
    "draft_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_1['Tokens'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the length of edits and of erasures -- find a way to find the most edited words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struck_through_tokens = token_flaubert_data('struck', flaubert_data)\n",
    "margins_tokens = token_flaubert_data('margins', flaubert_data)\n",
    "margins_no_struck_tokens = token_flaubert_data('margins_no_struck', flaubert_data)\n",
    "margins_struck_tokens = token_flaubert_data('margins_struck', flaubert_data)\n",
    "previous_struck_tokens = token_flaubert_data('previous_struck', flaubert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_data['struck_tokens'] = struck_through_tokens\n",
    "flaubert_data['margins_tokens'] = margins_tokens\n",
    "flaubert_data['margins_no_struck_tokens'] = margins_no_struck_tokens\n",
    "flaubert_data['margins_struck_tokens'] = margins_struck_tokens\n",
    "flaubert_data['previous_struck_tokens'] = previous_struck_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flaubert_struck_through = flaubert_data[['version', 'chapter', 'folio',\n",
    "                                        'struck', 'struck_tokens', \n",
    "                                        'previous_struck', 'previous_struck_tokens',\n",
    "                                        'margins', 'margins_tokens',\n",
    "                                        'margins_no_struck', 'margins_no_struck_tokens',\n",
    "                                        'margins_struck', 'margins_struck_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_columns_list = ['struck_tokens', 'previous_struck_tokens',\n",
    "                       'margins_tokens', 'margins_no_struck_tokens',\n",
    "                      'margins_struck_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_5_tokens_on_version(data, version_tag, extended_column_list):\n",
    "    versions = ['1', '2', '3', '4', '5', '6', 'C', 'D']\n",
    "    version_text = []\n",
    "    index = 0\n",
    "    for version in data['version']:\n",
    "        if version_tag == version:\n",
    "            version_text.extend(data[extended_column_list[0]][index])\n",
    "            version_text.extend(data[extended_column_list[1]][index])\n",
    "            version_text.extend(data[extended_column_list[2]][index])\n",
    "            version_text.extend(data[extended_column_list[3]][index])\n",
    "            version_text.extend(data[extended_column_list[4]][index])\n",
    "        index += 1\n",
    "    return version_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Struck Through Analysis: Comparing Different Versions\n",
    "\n",
    "By looking at every word that Flaubert and his copyiste struck through in Madame Bovary, we can see the differences in both the frequency and types of words that were edited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_1 = combine_tokens_on_version(flaubert_struck_through, '1', 'struck_tokens')\n",
    "version_2 = combine_tokens_on_version(flaubert_struck_through, '2', 'struck_tokens')\n",
    "version_3 = combine_tokens_on_version(flaubert_struck_through, '3', 'struck_tokens')\n",
    "version_4 = combine_tokens_on_version(flaubert_struck_through, '4', 'struck_tokens')\n",
    "version_5 = combine_tokens_on_version(flaubert_struck_through, '5', 'struck_tokens')\n",
    "version_6 = combine_tokens_on_version(flaubert_struck_through, '6', 'struck_tokens')\n",
    "version_c = combine_tokens_on_version(flaubert_struck_through, 'C', 'struck_tokens')\n",
    "version_d = combine_tokens_on_version(flaubert_struck_through, 'D', 'struck_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_1[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'version': ['1', '2', '3', '4', '5', '6', 'C', 'D'],\n",
    "        'struck_tokens': [version_1, version_2, version_3, version_4, version_5, version_6, version_c, version_d]}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_struck_versions = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flaubert_struck_versions.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_1_strikes_len = len(flaubert_struck_versions['struck_tokens'][0])\n",
    "version_1_strikes_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_2_strikes_len = len(flaubert_struck_versions['struck_tokens'][1])\n",
    "version_2_strikes_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_3_strikes_len = len(flaubert_struck_versions['struck_tokens'][2])\n",
    "version_3_strikes_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_4_strikes_len = len(flaubert_struck_versions['struck_tokens'][3])\n",
    "version_4_strikes_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_5_strikes_len = len(flaubert_struck_versions['struck_tokens'][4])\n",
    "version_5_strikes_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_6_strikes_len = len(flaubert_struck_versions['struck_tokens'][5])\n",
    "version_6_strikes_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_C_strikes_len = len(flaubert_struck_versions['struck_tokens'][6])\n",
    "version_C_strikes_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_D_strikes_len = len(flaubert_struck_versions['struck_tokens'][7])\n",
    "version_D_strikes_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strike_lengths = [version_1_strikes_len, version_2_strikes_len, version_3_strikes_len,\n",
    "                  version_4_strikes_len, version_5_strikes_len, version_6_strikes_len,\n",
    "                 version_C_strikes_len, version_D_strikes_len]\n",
    "\n",
    "versions = ['Brouillon 1', 'Brouillon 2', 'Brouillon 3', 'Brouillon 4', 'Brouillon 5', 'Brouillon 6', 'Copiste', 'Definitif']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of words struck through in each version\n",
    "plt.figure(figsize=[14, 10])\n",
    "plt.xlabel('Version')\n",
    "plt.ylabel('Number of Struck Through Words')\n",
    "plt.title('Frequency of Struck Through Words in Each Version of Madame Bovary')\n",
    "sns.barplot(x=versions, y=strike_lengths);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unedited Previous Text (prev_no_struck) Exploration: Comparing Different Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_version_table(column, original_frame):\n",
    "    version_key_list = ['1', '2', '3', '4', '5', '6', 'C', 'D']\n",
    "    \n",
    "    \n",
    "    def token_flaubert_data(column, dataframe):\n",
    "        folios_tokenized = []\n",
    "\n",
    "        for text in dataframe[column]:\n",
    "            if type(text)==str:\n",
    "                tokens = word_tokenizer.tokenize(text)\n",
    "                folios_tokenized.append(tokens)\n",
    "            else:\n",
    "                folios_tokenized.append(' ')\n",
    "        return folios_tokenized\n",
    "\n",
    "    tokenized_txt = token_flaubert_data(column, original_frame)\n",
    "    original_frame['tokens'] = tokenized_txt\n",
    "    original_frame = original_frame[['version', 'tokens']]\n",
    "    \n",
    "    version_1 = original_frame[original_frame['version'] == '1']\n",
    "    version_2 = original_frame[original_frame['version'] == '2']\n",
    "    version_3 = original_frame[original_frame['version'] == '3']\n",
    "    version_4 = original_frame[original_frame['version'] == '4']\n",
    "    version_5 = original_frame[original_frame['version'] == '5']\n",
    "    version_6 = original_frame[original_frame['version'] == '6']\n",
    "    version_C = original_frame[original_frame['version'] == 'C']\n",
    "    version_D = original_frame[original_frame['version'] == 'D']\n",
    "    \n",
    "    versions = [version_1, version_2, version_3, version_4, version_5, version_6, version_C, version_D]\n",
    "    \n",
    "    def concat_text(version_table):\n",
    "        full_text = []\n",
    "        for row in version_table['tokens']:\n",
    "            full_text += row\n",
    "        \n",
    "        return full_text\n",
    "    \n",
    "    concat_versions = [concat_text(version) for version in versions]\n",
    "    \n",
    "    final_frame = pd.DataFrame({'Version': version_key_list, 'Tokens': concat_versions})\n",
    "    \n",
    "    return final_frame\n",
    "    \n",
    "    \n",
    "    \n",
    "#     def combine_tokens_on_version(data, version_tag, extended_column):\n",
    "#         version_text = []\n",
    "#         index = 0\n",
    "#         for version in data['version']:\n",
    "#             if version_tag == version:\n",
    "#                 version_text.extend(data[extended_column][index])\n",
    "#             index += 1\n",
    "#         return version_text\n",
    "            \n",
    "    \n",
    "#     def collapse_versions(data, extended_column):\n",
    "#         versions = ['1', '2', '3', '4', '5', '6', 'C', 'D']\n",
    "#         full_version_tokens = []\n",
    "#         for version in versions:\n",
    "#             version_texty = combine_tokens_on_version(original_frame, version, 'tokens')\n",
    "#             full_version_tokens += version_texty\n",
    "                \n",
    "#         #version_frame = pd.DataFrame({'Version': version_key_list, 'Tokens': full_version_tokens}) \n",
    "#         return full_version_tokens\n",
    "    \n",
    "#     collapse_versions(original_frame, 'tokens')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_no_struck_tokens = initialize_version_table('previous_no_struck', flaubert_data)\n",
    "prev_no_struck_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_punct_versions(data, text_column):\n",
    "    list_punct = list(string.punctuation)\n",
    "    len_punct_list = []\n",
    "    for version in np.arange(8):\n",
    "        version_tab = data[text_column][version]\n",
    "        punct = [token for token in version_tab if token in list_punct]\n",
    "        len_punct = len(punct)\n",
    "        len_punct_list.append(len_punct)\n",
    "    return len_punct_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_punct_previous_no_struck = len_punct_versions(prev_no_struck_tokens, 'Tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14, 10])\n",
    "plt.title('Length of Total Unedited Punctuation')\n",
    "sns.barplot(x=versions, y=len_punct_previous_no_struck);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin Exploration: Comparing Different Versions\n",
    "\n",
    "By looking at the margins of the text, where words and comments were added to the text, we can where Flaubert and his copyiste focused their editing efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_1 = combine_tokens_on_version(flaubert_struck_through, '1', 'margins_tokens')\n",
    "version_2 = combine_tokens_on_version(flaubert_struck_through, '2', 'margins_tokens')\n",
    "version_3 = combine_tokens_on_version(flaubert_struck_through, '3', 'margins_tokens')\n",
    "version_4 = combine_tokens_on_version(flaubert_struck_through, '4', 'margins_tokens')\n",
    "version_5 = combine_tokens_on_version(flaubert_struck_through, '5', 'margins_tokens')\n",
    "version_6 = combine_tokens_on_version(flaubert_struck_through, '6', 'margins_tokens')\n",
    "version_c = combine_tokens_on_version(flaubert_struck_through, 'C', 'margins_tokens')\n",
    "version_d = combine_tokens_on_version(flaubert_struck_through, 'D', 'margins_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'version': ['1', '2', '3', '4', '5', '6', 'C', 'D'],\n",
    "        'margins_tokens': [version_1, version_2, version_3, version_4, version_5, version_6, version_c, version_d]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_margins_versions = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaubert_margins_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "version_c_margins_len = len(flaubert_margins_versions['margins_tokens'][6])\n",
    "print(version_c_margins_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = [token for token in flaubert_margins_versions['margins_tokens'][1] if token in (list(string.punctuation))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_punct_margins(key):\n",
    "    list_punct = list(string.punctuation)\n",
    "    version_tab = flaubert_margins_versions['margins_tokens'][key]\n",
    "    punct = [token for token in version_tab if token in list_punct]\n",
    "    return len(punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_key_list = ['1', '2', '3', '4', '5', '6', 'C', 'D']\n",
    "num_keys = np.arange(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_punct_margin = [len_punct_margins(version) for version in num_keys]\n",
    "len_punct_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14, 10])\n",
    "plt.title('Length of Total Punctuation in Margin')\n",
    "sns.barplot(x=versions, y=len_punct_margin);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_len(data, column):\n",
    "    len_list = []\n",
    "    for tokens in data[column]:\n",
    "        len_list.append(len(tokens))\n",
    "    return len_list\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_margins_list = gen_len(flaubert_margins_versions, 'margins_tokens')\n",
    "len_margins_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of words in margins in each version\n",
    "plt.figure(figsize=[14, 10])\n",
    "plt.xlabel('Version')\n",
    "plt.ylabel('Total Number of Words in Margin')\n",
    "plt.title('Frequency of Words in Margins of Each Version of Madame Bovary')\n",
    "sns.barplot(x=versions, y=len_margins_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strike_lengths + len_margins_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struck_df = pd.DataFrame({'Version': versions,\n",
    "                                 'Frequency': strike_lengths,\n",
    "                                 'Hue': ['Total Struck Through Text' for _ in np.arange(8)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_df = pd.DataFrame({'Version': versions,\n",
    "                                 'Frequency': len_margins_list,\n",
    "                                 'Hue': ['Total Margin Text' for _ in np.arange(8)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_struck_df = struck_df.append(margin_df)\n",
    "margin_struck_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14, 10])\n",
    "plt.xlabel('Version')\n",
    "plt.ylabel('Number of Words')\n",
    "plt.title('Comparison of Frequency of Words Crossed Out v. in Margins of Each Version of Madame Bovary')\n",
    "sns.barplot(data= margin_struck_df, x='Version', y='Frequency', hue='Hue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margins_no_struck_df = initialize_version_table('margins_no_struck', flaubert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_versions(data, text_column):\n",
    "    len_list = []\n",
    "    for version in np.arange(8):\n",
    "        len_version = len(data[text_column][version])\n",
    "        len_list.append(len_version)\n",
    "    return len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_margins_no_struck = len_versions(margins_no_struck_df, 'Tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_unedited_df = pd.DataFrame({'Version': versions,\n",
    "                                 'Frequency': len_margins_no_struck,\n",
    "                                 'Hue': ['Unedited Margin Text' for _ in np.arange(8)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_struck_unedit_df = struck_df.append(margin_unedited_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14, 10])\n",
    "plt.xlabel('Version')\n",
    "plt.ylabel('Number of Words')\n",
    "plt.title('Comparison of Frequency of Words Crossed Out v. in Margins of Each Version of Madame Bovary')\n",
    "sns.barplot(data= margin_struck_unedit_df, x='Version', y='Frequency', hue='Hue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_1 = pd.DataFrame([w for w in flaubert_version[flaubert_version['version'] == '1']['token_text']])\n",
    "draft_1 = draft_1.T\n",
    "draft_1['Tokens'] = draft_1[0]\n",
    "draft_1 = draft_1.drop(columns=[0])\n",
    "draft_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brouillons_1 = pd.DataFrame([w for w in flaubert_struck_versions[flaubert_struck_versions['version'] == '1']['struck_tokens']])\n",
    "brouillons_1 = brouillons_1.T\n",
    "brouillons_1['struck_tokens'] = brouillons_1[0]\n",
    "brouillons_1 = brouillons_1.drop(columns=[0])\n",
    "brouillons_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brouillons_2 = pd.DataFrame([w for w in flaubert_struck_versions[flaubert_struck_versions['version'] == '2']['struck_tokens']])\n",
    "brouillons_2 = brouillons_2.T\n",
    "brouillons_2['struck_tokens'] = brouillons_2[0]\n",
    "brouillons_2 = brouillons_2.drop(columns=[0])\n",
    "brouillons_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brouillons_3 = pd.DataFrame([w for w in flaubert_struck_versions[flaubert_struck_versions['version'] == '3']['struck_tokens']])\n",
    "brouillons_3 = brouillons_3.T\n",
    "brouillons_3['struck_tokens'] = brouillons_3[0]\n",
    "brouillons_3 = brouillons_3.drop(columns=[0])\n",
    "brouillons_3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brouillons_4 = pd.DataFrame([w for w in flaubert_struck_versions[flaubert_struck_versions['version'] == '4']['struck_tokens']])\n",
    "brouillons_4 = brouillons_4.T\n",
    "brouillons_4['struck_tokens'] = brouillons_4[0]\n",
    "brouillons_4 = brouillons_4.drop(columns=[0])\n",
    "brouillons_4.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brouillons_5 = pd.DataFrame([w for w in flaubert_struck_versions[flaubert_struck_versions['version'] == '5']['struck_tokens']])\n",
    "brouillons_5 = brouillons_5.T\n",
    "brouillons_5['struck_tokens'] = brouillons_5[0]\n",
    "brouillons_5 = brouillons_5.drop(columns=[0])\n",
    "brouillons_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brouillons_c = pd.DataFrame([w for w in flaubert_struck_versions[flaubert_struck_versions['version'] == 'C']['struck_tokens']])\n",
    "brouillons_c = brouillons_c.T\n",
    "brouillons_c['struck_tokens'] = brouillons_c[0]\n",
    "brouillons_c = brouillons_c.drop(columns=[0])\n",
    "brouillons_c.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brouillons_d = pd.DataFrame([w for w in flaubert_struck_versions[flaubert_struck_versions['version'] == 'D']['struck_tokens']])\n",
    "brouillons_d = brouillons_d.T\n",
    "brouillons_d['struck_tokens'] = brouillons_d[0]\n",
    "brouillons_d = brouillons_d.drop(columns=[0])\n",
    "brouillons_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"The current working directory is\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordPOSTagger as POS_Tag\n",
    "\n",
    "home = '/Users/mateomontoya/Desktop'\n",
    "\n",
    "_path_to_model = home + '/stanford-postagger/models/french.tagger' \n",
    "_path_to_jar = home + '/stanford-postagger/stanford-postagger.jar'\n",
    "st = POS_Tag(_path_to_model, _path_to_jar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.tag(\"Je n'aime pas Madame Bovary de Flaubert\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_draft_1 = st.tag(brouillons_1['struck_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_tag_draft_1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_brouillons_1 = pd.DataFrame({'Tokens': [w[0] for w in pos_tag_draft_1],\n",
    "                                     'POS_Tag': [w[1] for w in pos_tag_draft_1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_brouillons_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_brouillons_1['POS_Tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_1_pos_count = pd.DataFrame(pos_tag_brouillons_1['POS_Tag'].value_counts()[:15])\n",
    "b_1_pos_count.reset_index(inplace=True)\n",
    "b_1_pos_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_POS_tags = ['P', 'NC', 'DET', 'V', 'ADV', 'PUNC', 'CLS', 'N', 'CC', 'ADJ', 'VINF', 'VPP', 'CLO', 'PRO', 'CLR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_1_pos_count_select = b_1_pos_count[b_1_pos_count['index'].isin(selected_POS_tags)]\n",
    "b_1_pos_count_select = b_1_pos_count_select.rename(index=str, columns={'POS_Tag': 'Count', 'index': 'POS_Tag'})\n",
    "b_1 = ['Brouillons_1' for _ in range(14)]\n",
    "b_1_pos_count_select['Version'] = b_1\n",
    "b_1_pos_count_select.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_definitif = st.tag(brouillons_d['struck_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_definitif_data = pd.DataFrame({'Tokens': [w[0] for w in pos_tag_definitif],\n",
    "                                     'POS_Tag': [w[1] for w in pos_tag_definitif]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_definitif_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_definitif_data['POS_Tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def_pos_count = pd.DataFrame(data=pos_tag_definitif_data['POS_Tag'].value_counts())\n",
    "def_pos_count = def_pos_count.reset_index()\n",
    "def_pos_count.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_pos_count_select = def_pos_count[def_pos_count['index'].isin(selected_POS_tags)]\n",
    "def_pos_count_select = def_pos_count_select.rename(index=str, columns={'POS_Tag': 'Count', 'index': 'POS_Tag'})\n",
    "definitif = ['Definitif' for _ in range(15)]\n",
    "def_pos_count_select['Version'] = definitif\n",
    "def_pos_count_select.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_counts_appended = b_1_pos_count_select.append(def_pos_count_select, ignore_index=True)\n",
    "POS_counts_appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "POS_counts_merged = b_1_pos_count_select.merge(def_pos_count_select, on='POS_Tag')\n",
    "POS_counts_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14, 10])\n",
    "plt.title('Compared POS Tag Frequency of Top 15 POS Tags of Struck Words in First Draft and Final Edition')\n",
    "sns.barplot(data=POS_counts_appended, x='POS_Tag', y='Count', hue='Version');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14, 10])\n",
    "plt.title('Compared POS Tag Frequency of Top 15 POS Tags in Final Draft')\n",
    "sns.barplot(x=POS_counts_merged['POS_Tag'], y=POS_counts_merged['Count_y']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nouns, Adjectives, Proper Nouns, Adverbs, Punctuation, Conjunctions - The Frugal Editor -- Naddaff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We distinguish 15 lexical categories, used for simple words as well as for compounds:\n",
    "\n",
    "- A (adjective)\n",
    "- Adv (adverb)\n",
    "- CC (coordinating conjunction)\n",
    "- Cl (weak clitic pronoun)\n",
    "- CS (subordinating conjunction)\n",
    "- D (determiner)\n",
    "- ET (foreign word)\n",
    "- I (interjection)\n",
    "- NC (common noun)\n",
    "- NP (proper noun)\n",
    "- P (preposition)\n",
    "- PREF (prefix)\n",
    "- PRO (strong pronoun)\n",
    "- V (verb)\n",
    "- PONCT (punctuation mark)\n",
    "\n",
    "Our phrasal tagset is as follows:\n",
    "\n",
    "- AP (adjectival phrases)\n",
    "- AdP (adverbial phrases)\n",
    "- COORD (coordinated phrases)\n",
    "- NP (noun phrases)\n",
    "- PP (prepositional phrases)\n",
    "- VN (verbal nucleus)\n",
    "- VPinf (infinitive clauses)\n",
    "- VPpart (nonfinite clauses)\n",
    "- SENT (sentences)\n",
    "- Sint, Srel, Ssub (finite clauses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Text (Margin and Struckthrough Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_1 = pd.DataFrame([w for w in flaubert_version[flaubert_version['version'] == '1']['token_text']])\n",
    "draft_1 = draft_1.T\n",
    "draft_1['Tokens'] = draft_1[0]\n",
    "draft_1 = draft_1.drop(columns=[0])\n",
    "draft_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draft_1 = pd.DataFrame([w for w in flaubert_version[flaubert_version['version'] == '1']['token_text']])\n",
    "draft_1 = draft_1.T\n",
    "draft_1['Tokens'] = draft_1[0]\n",
    "draft_1 = draft_1.drop(columns=[0])\n",
    "draft_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listy = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_1_punct = draft_1[draft_1['Tokens'].isin(listy)]\n",
    "len(draft_1_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_2 = pd.DataFrame([w for w in flaubert_version[flaubert_version['version'] == '2']['token_text']])\n",
    "draft_2 = draft_2.T\n",
    "draft_2['Tokens'] = draft_2[0]\n",
    "draft_2 = draft_2.drop(columns=[0])\n",
    "draft_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_3 = pd.DataFrame([w for w in flaubert_version[flaubert_version['version'] == '3']['token_text']])\n",
    "draft_3 = draft_3.T\n",
    "draft_3['Tokens'] = draft_3[0]\n",
    "draft_3 = draft_3.drop(columns=[0])\n",
    "draft_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_4 = pd.DataFrame([w for w in flaubert_version[flaubert_version['version'] == '4']['token_text']])\n",
    "draft_4 = draft_4.T\n",
    "draft_4['Tokens'] = draft_4[0]\n",
    "draft_4 = draft_4.drop(columns=[0])\n",
    "draft_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_5 = pd.DataFrame([w for w in flaubert_version[flaubert_version['version'] == '5']['token_text']])\n",
    "draft_5 = draft_5.T\n",
    "draft_5['Tokens'] = draft_5[0]\n",
    "draft_5 = draft_5.drop(columns=[0])\n",
    "draft_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_6 = pd.DataFrame([w for w in flaubert_version[flaubert_version['version'] == '6']['token_text']])\n",
    "draft_6 = draft_6.T\n",
    "draft_6['Tokens'] = draft_6[0]\n",
    "draft_6 = draft_6.drop(columns=[0])\n",
    "draft_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copiste = pd.DataFrame([w for w in flaubert_version[flaubert_version['version'] == 'C']['token_text']])\n",
    "copiste = copiste.T\n",
    "copiste['Tokens'] = copiste[0]\n",
    "copiste = copiste.drop(columns=[0])\n",
    "copiste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitif = pd.DataFrame([w for w in flaubert_version[flaubert_version['version'] == 'D']['token_text']])\n",
    "definitif = definitif.T\n",
    "definitif['Tokens'] = definitif[0]\n",
    "definitif = definitif.drop(columns=[0])\n",
    "definitif.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_punct(version):\n",
    "    list_punct = list(string.punctuation)\n",
    "    punct = version[version['Tokens'].isin(list_punct)]\n",
    "    return len(punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_versions = [draft_1, draft_2, draft_3, draft_4, draft_5, draft_6, copiste, definitif]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_punc_versions = [len_punct(version) for version in list_versions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tot_punc_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14, 10])\n",
    "plt.title('Length of Total Punctuation in Each Version')\n",
    "sns.barplot(x=versions, y=tot_punc_versions);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Compared: Margin and Unedited Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_punct_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_punct_previous_no_struck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_marg_unedit_punc = list(map(np.add, len_punct_margin, len_punct_previous_no_struck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_marg_unedit_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14, 10])\n",
    "plt.title('Quanitity Punctuation in Each Version')\n",
    "sns.barplot(x=versions, y=len_marg_unedit_punc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_1_pos = st.tag(draft_1['Tokens'])\n",
    "draft_1_pos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import CoreNLPParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger = CoreNLPParser('http://localhost:9004', tagtype= 'pos')\n",
    "pos_tagger.tag('Je suis enceinte'.split())\n",
    "[('Je', 'PRON'), ('suis', 'VERB'), ('enceinte', 'ADJ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feminine vs. Masculine writing -- La Martine as a feminine writer -- need to generate a bag of words to control for this -- Flaubert's earlier writings were more feminine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
